### elizaOS Environment Variables ###
# To get started, copy this file to .env, or make a .env and add the settings you'd like to override
# Please read the comments for each of the configurations

## The only thing you ABSOLUTELY NEED to get up and running is one of the model provider keys,
## i.e. OPENAI_API_KEY or ANTHROPIC_API_KEY, or setup the local-ai or ollama plugin
## Everything else is optional, and most settings and secrets can be configured in your agent or through the GUI
## For multi-agent, each agent will need keys for the various services it is connected to
-------------------------------
## You can use the .env or environment variables generally for shared keys, such as to model providers,
## database, etc, with scoped keys for services such as Telegram, Discord, etc

## MODEL PROVIDER KEYS ##
## Eliza is compatible with a wide array of model providers. Many have OpenAI compatible APIs,
## and you can use them by overriding the base URL

## NOTE: You will need a provider that provides embeddings. So even if you use Claude, you will
## need to get embeddings using another provider, for example openai or our local-ai plugin

# OpenAI Configuration
## Use this to override the openai endpoint, for example for using together.ai, fireworks or other providers
## Optional overrides:
--------------------------------
# OPENAI_BASE_URL=
# OPENAI_SMALL_MODEL=gpt-4o-mini
# OPENAI_LARGE_MODEL=gpt-4o
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_EMBEDDING_URL=
# OPENAI_EMBEDDING_DIMENSIONS=1536
# OPENAI_IMAGE_DESCRIPTION_MODEL=gpt-4o-mini
# OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS=8192

# Anthropic Configuration
## By default in most of our starter kits, Anthropic will take precedence over OpenAI in handling requests
## Anthropic does not handle embeddings, so you may wish to use OpenAI for that, even while Claude is handling text generation
--------------------------------
ANTHROPIC_API_KEY=
# Optional overrides:
# ANTHROPIC_SMALL_MODEL=claude-3-5-haiku-latest
# ANTHROPIC_LARGE_MODEL=claude-3-5-sonnet-latest


# Ollama Configuration
## Highly recommended to use gemma3:latest for text generation
--------------------------------
# OLLAMA_API_ENDPOINT=http://localhost:11434/api
# OLLAMA_SMALL_MODEL=gemma3:latest
# OLLAMA_MEDIUM_MODEL=gemma3:latest
# OLLAMA_LARGE_MODEL=gemma3:latest


# Local AI Configuration
## REMEMBER A GOOD AMOUNT OF VRAM IS NEEDED FOR THE LARGE LOCAL MODELS
--------------------------------
# LOCAL_SMALL_MODEL=DeepHermes-3-Llama-3-3B-Preview-q4.gguf
# LOCAL_LARGE_MODEL=DeepHermes-3-Llama-3-70B-Preview-q4.gguf
# LOCAL_EMBEDDING_MODEL=bge-small-en-v1.5.Q4_K_M.gguf




# Highly recommended to use nomic-embed-text for embeddings
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text

### DATABASE ###
# By default, Eliza will use a local pglite instance
# If you fill out POSTGRES_URL, the agent will connect to your postgres instance instead of using the local path

# You can override the pglite data directory

# Fill this out if you want to use Postgres
POSTGRES_URL=

### LOGGING CONFIGURATION ###
# Logging Configuration (supported: fatal, error, warn, info, debug, trace | default: info)
LOG_LEVEL=


# Sentry Configuration
--------------------------------
## DO NOT CHANGE THIS UNLESS YOU KNOW WHAT YOU ARE DOING
--------------------------------
# Sentry is a tool for monitoring and logging errors and exceptions
# It is used to track errors and exceptions in the agent
--------------------------------
# Sentry Configuration
SENTRY_LOGGING=true
SENTRY_DSN=
SENTRY_ENVIRONMENT=
SENTRY_TRACES_SAMPLE_RATE=
SENTRY_SEND_DEFAULT_PII=


PGLITE_DATA_DIR=
OPENAI_API_KEY=

DISCORD_APPLICATION_ID=
DISCORD_API_TOKEN=

# Farcaster Configuration
FARCASTER_NEYNAR_API_KEY=
FARCASTER_SIGNER_UUID=
FARCASTER_FID=

# Farcaster Settings (optional)
FARCASTER_DRY_RUN=false
ENABLE_POST=true
POST_INTERVAL_MIN=
POST_INTERVAL_MAX=
ENABLE_ACTION_PROCESSING=true
ACTION_INTERVAL=